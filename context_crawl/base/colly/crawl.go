// file: colly_crawler.go
/*

ç®€æ˜“ Web çˆ¬è™«ï¼Œä½¿ç”¨ Colly åº“ï¼Œå¹¶é™åˆ¶æœ€å¤§å¹¶å‘æ•°ã€‚

æ•´ç†è®¾è®¡å€¾å‘äºä»£ç æœç´¢ï¼Œé’ˆå¯¹ä»£ç çš„æå–è¿›è¡Œäº†ä¸€ç³»åˆ—ä¼˜åŒ–

*/
package colly

import (
	"context"
	"fmt"
	"log"
	"net"
	"net/http"
	"os"
	"strings"
	"sync"
	"time"

	"github.com/PuerkitoBio/goquery"
	"github.com/chromedp/chromedp"
	"github.com/gocolly/colly/v2"

	"context_crawl/types"
)

// CollyCrawler å®ç°äº†åŸºäºCollyçš„çˆ¬è™«

type CollyCrawler struct {
	MaxConcurrent  int           // æœ€å¤§å¹¶å‘æ•°
	RequestTimeout time.Duration // è¯·æ±‚è¶…æ—¶æ—¶é—´
}

// NewCollyCrawler åˆ›å»ºä¸€ä¸ªæ–°çš„CollyCrawlerå®ä¾‹
func NewCollyCrawler() *CollyCrawler {
	return &CollyCrawler{
		MaxConcurrent:  60,               // é»˜è®¤æœ€å¤§å¹¶å‘æ•°
		RequestTimeout: 15 * time.Second, // é»˜è®¤è¯·æ±‚è¶…æ—¶15ç§’
	}
}

// å¼‚æ­¥Chromedpå°è£…
type FetchResult struct {
	URL  string
	HTML string
	Err  error
}

// semaphore æ§åˆ¶æœ€å¤§å¹¶å‘
var chromedpSem = make(chan struct{}, 3) // æœ€å¤š 3 ä¸ªåŠ¨æ€é¡µé¢åŒæ—¶æŠ“å–
var wg sync.WaitGroup

// é»˜è®¤é‡è¯•æ¬¡æ•°ï¼ˆæ€»å…±å°è¯•4æ¬¡ï¼‰
const MaxRetries = 3

// æŒ‡æ•°é€€é¿æ—¶é—´ï¼ˆè¾ƒé•¿çš„æ—¶é—´ï¼‰
func getBackoffDelay(retryCount int) time.Duration {
	// ä½¿ç”¨è¾ƒé•¿çš„æŒ‡æ•°é€€é¿ï¼š1s, 2s, 4s
	return time.Duration(1<<uint(retryCount)) * 1000 * time.Millisecond
}

// åˆ¤æ–­é”™è¯¯æ˜¯å¦åº”è¯¥é‡è¯•
func shouldRetry(err error) bool {
	if err == nil {
		return false
	}

	// æ£€æŸ¥é”™è¯¯ç±»å‹
	errStr := err.Error()

	// è¿æ¥é”™è¯¯
	if strings.Contains(errStr, "connection refused") ||
		strings.Contains(errStr, "no such host") ||
		strings.Contains(errStr, "network is unreachable") ||
		strings.Contains(errStr, "timeout") {
		return true
	}

	// HTTPçŠ¶æ€ç é”™è¯¯
	if strings.Contains(errStr, "408") || // è¯·æ±‚è¶…æ—¶
		strings.Contains(errStr, "409") || // å†²çª
		strings.Contains(errStr, "429") || // é€Ÿç‡é™åˆ¶
		strings.Contains(errStr, "500") || // å†…éƒ¨é”™è¯¯
		strings.Contains(errStr, "502") || // ç½‘å…³é”™è¯¯
		strings.Contains(errStr, "503") || // æœåŠ¡ä¸å¯ç”¨
		strings.Contains(errStr, "504") { // ç½‘å…³è¶…æ—¶
		return true
	}

	return false
}

func FetchPageAsync(url string, resultChan chan<- FetchResult) {
	wg.Add(1)
	chromedpSem <- struct{}{} // è·å– token
	go func() {
		defer wg.Done()
		defer func() { <-chromedpSem }() // é‡Šæ”¾ token

		var html string
		var err error

		// é‡è¯•æœºåˆ¶ï¼šé»˜è®¤é‡è¯•3æ¬¡ï¼ˆæ€»å…±4æ¬¡å°è¯•ï¼‰
		for i := 0; i <= MaxRetries; i++ {
			// è®¾ç½®ä»£ç†é€‰é¡¹
			opts := []chromedp.ExecAllocatorOption{
				chromedp.NoFirstRun,
				chromedp.NoDefaultBrowserCheck,
				chromedp.Headless,
			}

			// æ·»åŠ ä»£ç†è®¾ç½®
			if proxy := os.Getenv("http_proxy"); proxy != "" {
				opts = append(opts, chromedp.ProxyServer(proxy))
			} else if proxy := os.Getenv("https_proxy"); proxy != "" {
				opts = append(opts, chromedp.ProxyServer(proxy))
			}

			allocCtx, cancel := chromedp.NewExecAllocator(context.Background(), opts...)
			defer cancel()
			ctx, cancel := chromedp.NewContext(allocCtx)
			defer cancel()
			ctx, cancel = context.WithTimeout(ctx, 10*time.Second) // å•æ¬¡è¯·æ±‚10ç§’è¶…æ—¶
			defer cancel()

			// ç­‰å¾…æ—¶é—´æ ¹æ®é‡è¯•æ¬¡æ•°é€’å¢ï¼š2s, 3s, 4s, 5s
			waitTime := 2 + time.Duration(i)*time.Second
			err = chromedp.Run(ctx,
				chromedp.Navigate(url),
				chromedp.Sleep(waitTime), // æ ¹æ®é‡è¯•æ¬¡æ•°é€’å¢ç­‰å¾…æ—¶é—´
				chromedp.OuterHTML("html", &html),
			)

			if err == nil {
				// æ£€æŸ¥æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
				if !containsErrorMessages(html) {
					break // æˆåŠŸä¸”æ— é”™è¯¯ä¿¡æ¯åˆ™é€€å‡ºé‡è¯•å¾ªç¯
				}
				// å¦‚æœåŒ…å«é”™è¯¯ä¿¡æ¯ï¼Œç»§ç»­é‡è¯•
				log.Printf("âš ï¸ æ£€æµ‹åˆ°é¡µé¢é”™è¯¯ä¿¡æ¯ï¼Œç¬¬%dæ¬¡é‡è¯•", i+1)
			}

			// æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
			if i < MaxRetries && shouldRetry(err) {
				backoff := getBackoffDelay(i)
				log.Printf("âš ï¸ ç¬¬%dæ¬¡æŠ“å–å¤±è´¥ï¼Œ%vç§’åé‡è¯•: %v", i+1, backoff.Seconds(), err)
				time.Sleep(backoff)
			} else {
				// ä¸åº”è¯¥é‡è¯•æˆ–å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç›´æ¥é€€å‡º
				if i < MaxRetries {
					log.Printf("âŒ é”™è¯¯ä¸å¯é‡è¯•ï¼Œæ”¾å¼ƒæŠ“å–: %v", err)
				}
				break
			}
		}

		resultChan <- FetchResult{
			URL:  url,
			HTML: html,
			Err:  err,
		}
	}()
}
func (cc *CollyCrawler) Crawl(input types.Type) (types.Type, error) {
	fmt.Println("ğŸš€ å¼€å§‹çˆ¬å–ç½‘é¡µ...")
	start := time.Now()
	var result types.Type
	resultChan := make(chan types.Type, 1)
	// dynamicResultChan := make(chan FetchResult, 1) // ç¦ç”¨åŠ¨æ€æŠ“å–åä¸å†éœ€è¦

	// å…¨å±€è¶…æ—¶ï¼š60 ç§’å†…å¿…é¡»ç»“æŸï¼ˆè€ƒè™‘åˆ°é‡è¯•æœºåˆ¶ï¼‰
	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	// å¤šä¸ªç”¨æˆ·ä»£ç†è½®æ¢
	userAgents := []string{
		"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
		"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
		"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
		"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
		"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15",
	}

	// Colly åˆå§‹åŒ– - ä½¿ç”¨åŒæ­¥æ¨¡å¼
	c := colly.NewCollector(
		colly.Async(false), // ä½¿ç”¨åŒæ­¥æ¨¡å¼
		colly.MaxDepth(1),
	)
	// éšæœºé€‰æ‹©ç”¨æˆ·ä»£ç†
	c.UserAgent = userAgents[time.Now().UnixNano()%int64(len(userAgents))]
	c.AllowURLRevisit = false

	// ä¸ä½¿ç”¨ä»£ç†ï¼Œç›´æ¥è¿æ¥
	log.Printf("ä¸ä½¿ç”¨ä»£ç†ï¼Œç›´æ¥è¿æ¥")
	c.WithTransport(&http.Transport{
		Proxy: nil, // ç¦ç”¨ä»£ç†
		DialContext: (&net.Dialer{
			Timeout:   10 * time.Second,
			KeepAlive: 10 * time.Second,
		}).DialContext,
		TLSHandshakeTimeout:   10 * time.Second,
		ResponseHeaderTimeout: 10 * time.Second,
	})

	// ç®€åŒ–é™åˆ¶è®¾ç½®
	c.Limit(&colly.LimitRule{
		DomainGlob:  "*",
		Parallelism: 1,                      // åŒæ­¥æ¨¡å¼ä¸‹è®¾ç½®ä¸º1
		Delay:       500 * time.Millisecond, // é€‚å½“å»¶è¿Ÿ
	})

	// é™æ€é¡µé¢
	c.OnHTML("body", func(e *colly.HTMLElement) {
		select {
		case <-ctx.Done():
			return
		default:
		}

		e.DOM.Find("script, style, noscript").Each(func(i int, s *goquery.Selection) {
			s.Remove()
		})
		html, err := e.DOM.Html()
		if err != nil {
			log.Println("âŒ ç½‘é¡µè§£æå¤±è´¥:", e.Request.URL, err)
			return
		}
		// æš‚æ—¶ç¦ç”¨åŠ¨æ€æŠ“å–ï¼Œä¼˜å…ˆè¿”å›é™æ€ç»“æœ
		// if needsJS(html) {
		//  FetchPageAsync(e.Request.URL.String(), dynamicResultChan)
		//  return
		// }
		select {
		case resultChan <- types.Type{Url: e.Request.URL.String(), Text: html}:
		case <-ctx.Done():
		}
	})

	c.OnError(func(r *colly.Response, err error) {
		log.Printf("âŒ Error: %v, URL: %s, StatusCode: %d", err, r.Request.URL, r.StatusCode)
		// å¯¹äºè¶…æ—¶é”™è¯¯ï¼Œè®°å½•æ›´è¯¦ç»†çš„ä¿¡æ¯
		if netErr, ok := err.(net.Error); ok && netErr.Timeout() {
			log.Printf("â° è¯·æ±‚è¶…æ—¶ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–é¡µé¢å“åº”æ…¢")
		}
	})

	// å¤„ç†å•ä¸ªè¾“å…¥
	url := input.Url
	// ä½¿ç”¨Collyçˆ¬å–ç½‘ç»œé¡µé¢
	c.Visit(url)
	// åŒæ­¥æ¨¡å¼ä¸‹ä¸éœ€è¦Wait()
	// c.Wait()

	// å…³é—­resultChanï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»ç¦ç”¨äº†åŠ¨æ€æŠ“å–
	close(resultChan)

	// å¤„ç†ç½‘ç»œçˆ¬å–çš„ç»“æœ
	done := make(chan struct{})
	go func() {
		for r := range resultChan {
			result = r
			break // åªå–ç¬¬ä¸€ä¸ªç»“æœ
		}
		close(done)
	}()

	select {
	case <-ctx.Done(): // è¶…æ—¶ç›´æ¥è¿”å›
		fmt.Println("â° çˆ¬å–è¶…æ—¶ï¼Œè¿”å›ç©ºç»“æœ")
		return types.Type{}, fmt.Errorf("çˆ¬å–è¶…æ—¶")
	case <-done:
		fmt.Println("âœ… ç½‘é¡µçˆ¬å–å®Œæˆ")
	}

	fmt.Println("æ€»è€—æ—¶:", time.Since(start))
	return result, nil
}

// æ¸…æ´—æ–‡æœ¬ï¼Œä¿ç•™ä»£ç å—å ä½ç¬¦
// æ¸…æ´—æ–‡æœ¬ï¼Œä¿ç•™ä»£ç å—å ä½ç¬¦
// è¾…åŠ©å‡½æ•°
// åˆ¤æ–­ç½‘é¡µæ˜¯å¦éœ€è¦ JS æ¸²æŸ“
func needsJS(html string) bool {
	// å¦‚æœ body å†…å®¹å¤ªçŸ­ï¼Œå°±è®¤ä¸ºæ˜¯åŠ¨æ€é¡µé¢
	if len(html) < 100 {
		return true
	}

	// åˆ¤æ–­æ˜¯å¦æœ‰å¸¸è§çš„ JS æ¡†æ¶æ ‡è¯†
	jsFrameworks := []string{
		"id=\"app\"",
		"id=\"root\"",
		"id=\"__next\"",
		"react-root",
		"vue-app",
		"ng-app",
		"data-reactroot",
	}

	for _, framework := range jsFrameworks {
		if strings.Contains(strings.ToLower(html), strings.ToLower(framework)) {
			log.Printf("ğŸ” æ£€æµ‹åˆ°JSæ¡†æ¶æ ‡è¯†: %s", framework)
			return true
		}
	}

	// æ£€æŸ¥æ˜¯å¦åŒ…å«å¤§é‡JavaScriptä»£ç 
	if strings.Count(html, "<script") > 10 {
		log.Printf("ğŸ” æ£€æµ‹åˆ°å¤§é‡scriptæ ‡ç­¾ï¼Œå¯èƒ½æ˜¯åŠ¨æ€é¡µé¢")
		return true
	}

	return false
}

// æ£€æµ‹é¡µé¢æ˜¯å¦åŒ…å«é”™è¯¯ä¿¡æ¯
func containsErrorMessages(html string) bool {
	errorPatterns := []string{
		"Uh oh! There was an error while loading",
		"Please reload this page",
		"Something went wrong",
		"An error occurred",
		"Error loading",
		"Failed to load",
	}

	lowerHTML := strings.ToLower(html)
	for _, pattern := range errorPatterns {
		if strings.Contains(lowerHTML, strings.ToLower(pattern)) {
			log.Printf("âš ï¸ æ£€æµ‹åˆ°é”™è¯¯ä¿¡æ¯: %s", pattern)
			return true
		}
	}

	return false
}
